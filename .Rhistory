barplot(table(dado))
dado <- sample(x=1:6, size=10000, replace = TRUE)
print(dado)
sum(dado == 3)
mean(dado == 3)  #ou sum(dado == 3)/10000
barplot(table(dado))
table(idoso$Survived)
idoso <- dados[dados$Age >= 60,]
treinamento <- iris[1:n,]
iris
iris <- iris[sample(nrow(iris)),]
iris
n <- round(0.8*nrow(iris))
n
treinamento <- iris[1:n,]
teste <- iris[-(1:n),]
summary(teste)
ggplot(data = treinamento, aes(x = Petal.Length, y = Petal.Width, col = Species)) +
geom_point(size = 2, alpha = 0.5)+
theme_minimal()
iris
iris <- iris[sample(nrow(iris)),]
iris
n <- round(0.8*nrow(iris))
n
treinamento <- iris[1:n,]
teste <- iris[-(1:n),]
summary(teste)
ggplot(data = treinamento, aes(x = Petal.Length, y = Petal.Width, col = Species)) +
geom_point(size = 2, alpha = 0.5)+
theme_minimal()
library(ggplot2)
iris
iris <- iris[sample(nrow(iris)),]
iris
n <- round(0.8*nrow(iris))
n
treinamento <- iris[1:n,]
teste <- iris[-(1:n),]
summary(teste)
ggplot(data = treinamento, aes(x = Petal.Length, y = Petal.Width, col = Species)) +
geom_point(size = 2, alpha = 0.5)+
theme_minimal()
library(randomForest)
cancer <- read.table(file = "cancer.csv", sep = ",", header = TRUE)
cancer <- na.omit(cancer)
str(cancer)
n <- round(0.8*nrow(cancer))
indices_treino <- sample(1:nrow(cancer), size = n, replace = FALSE)
treino <- cancer[indices_treino,]
install.packages(randomForest)
install.packages('randomForest')
library(randomForest)
install.packages('randomForest')
library(randomForest)
library(randomForest)
install.packages('randomForest')
library(randomForest)
cancer <- read.table(file = "cancer.csv", sep = ",", header = TRUE)
cancer <- na.omit(cancer)
library(randomForest)
library(rvest)
library(dplyr)
library(stringr)
library(geobr)
library(ggplot2)
url <- "https://pt.wikipedia.org/wiki/Lista_de_unidades_federativas_do_Brasil_por_alfabetiza%C3%A7%C3%A3o"
html <- read_html(url)
tabelas <- html |>
html_elements("table") |>
html_table()
View(tabelas)
alfabetizacao <- tabelas[[3]]
View(alfabetizacao)
alfabetizacao <- alfabetizacao[,c(2,3)]
names(alfabetizacao) <- c("estado", "taxa")
names(alfabetizacao)
parte1 <- str_replace_all(alfabetizacao$taxa, pattern = ",", replacement = ".")
parte2 <- str_replace_all(string = parte1, pattern = "%", replacement = "")
parte_final <- as.numeric(parte2)
alfabetizacao$taxa <- parte_final
minas <- read_state(code_state = "MG")
ggplot(data = minas) +
theme_minimal() +
geom_sf()
municipioMG <- read_municipality(code_muni = "MG")
ggplot(data = municipioMG) +
theme_minimal()+
geom_sf()
estados <- read_state()
estados$name_state
order(estados$name_state)
estados[2,]
estados <- estados[order(estados$name_state),]
estados
alfabetizacao <- alfabetizacao[order(alfabetizacao$estado),]
alfabetizacao$estado
estados <- estados[order(estados$name_state),]
estados$taxa <- alfabetizacao$taxa
ggplot(data = estados, aes(fill = taxa)) +
geom_sf()+
scale_fill_gradient(low = '#56b1f7', high = '#132b43')
gc()
library(rvest)
library(dplyr)
url <- "https://www.bbc.com/portuguese/articles/cql3lwgl3ldo"
html <- read_html(url)
html
titulo <- html |>
html_elements('h1') |>
html_text2()
titulo <- ("Editar DNA é ético? O debate sobre tecnologia que promete revolucionar vidas")
html |>
html_elements("p") |>
html_text2()
html |>
html_elements("p.bbc-hhl7in") |>
html_text2()
setwd("~/Documentos/Estatística Computacional")
noticia <- paste(noiticia, collapse= " ")
artigos <- data.frame(titulo, noticia)
noticia <- html |>
html_elements("p.bbc-hhl7in") |>
html_text2()
noticia <- paste(noticia, collapse= " ")
artigos <- data.frame(titulo, noticia)
View(html)
View(artigos)
library(tidytext)
url <- "https://www.bbc.com/portuguese/articles/cql3lwgl3ldo"
html <- read_html(url)
html
titulo <- html |>
html_elements('h1') |>
html_text2()
titulo <- ("Editar DNA é ético? O debate sobre tecnologia que promete revolucionar vidas")
noticia <- html |>
html_elements("p.bbc-hhl7in") |>
html_text2()
noticia <- paste(noticia, collapse= " ")
artigos <- data.frame(titulo, noticia)
library(tidytext)
|>
|>
artigos|>
unnest_tokens()
artigos <- data.frame(titulo, noticia)
library(tidytext)
artigos|>
unnest_tokens()
artigos|>
unnest_tokens(output = words, input = noticia)
artigos|>
unnest_tokens(output = words, input = noticia) |>
count(words)
artigos|>
unnest_tokens(output = words, input = noticia) |>
count(words) |>
arrange(desc(n))
